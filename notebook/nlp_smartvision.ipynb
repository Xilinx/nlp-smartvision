{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Xilinx Logo](images/xilinx_logo.png \"Xilinx Logo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction:\n",
    "\n",
    "This notebook demonstrates how to run the Live Audio + Video Example on SOM module.\n",
    "\n",
    "    Audio --> Keyword Spotting (KWS) from Live Audio Source.\n",
    "\n",
    "    Video --> 1. Face Detection\n",
    "              2. Object Detection \n",
    "              3. Number Plate Detection\n",
    "\n",
    "In this demo, both speech and vision input streams are captured and processed in parallel on a single device. The demo is capable to detect a keyword and perform predefined tasks mapped to those particular keywords.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Motivation](images/Motivation.png \"Motivation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List of Tasks and their corresponding Keyword Mapping \n",
    "\n",
    "The 10 Keywords from Google Command dataset shown below are mapped to 10 spearate tasks for all the three tasks. For details please refer the below figure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Mapping](images/KWS_AV_Solution.png \"Mapping\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup the Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting pipeline to PAUSED ...\n",
      "Pipeline is live and does not need PREROLL ...\n",
      "/GstPipeline:pipeline0/GstKMSSink:kmssink0: display-width = 1920\n",
      "/GstPipeline:pipeline0/GstKMSSink:kmssink0: display-height = 1080\n",
      "/GstPipeline:pipeline0/GstMediaSrcBin:mediasrcbin0/GstV4l2Src:v4l2src0: io-mode = GST_V4L2_IO_DMABUF_IMPORT\n",
      "/GstPipeline:pipeline0/GstCapsFilter:capsfilter1: caps = video/x-raw, width=(int)1024, height=(int)768, format=(string)RGB, framerate=(fraction)30/1\n",
      "/GstPipeline:pipeline0/GstMediaSrcBin:mediasrcbin0/GstV4l2Src:v4l2src0.GstPad:src: caps = video/x-raw, width=(int)1024, height=(int)768, format=(string)RGB, framerate=(fraction)30/1, interlace-mode=(string)progressive, colorimetry=(string)sRGB\n",
      "/GstPipeline:pipeline0/GstMediaSrcBin:mediasrcbin0.GstMediaSrcBinPad:src_0: caps = video/x-raw, width=(int)1024, height=(int)768, format=(string)RGB, framerate=(fraction)30/1, interlace-mode=(string)progressive, colorimetry=(string)sRGB\n",
      "/GstPipeline:pipeline0/GstCapsFilter:capsfilter1.GstPad:src: caps = video/x-raw, width=(int)1024, height=(int)768, format=(string)RGB, framerate=(fraction)30/1, interlace-mode=(string)progressive, colorimetry=(string)sRGB\n",
      "Setting pipeline to PLAYING ...\n",
      "New clock: GstSystemClock\n",
      "/GstPipeline:pipeline0/GstKMSSink:kmssink0.GstPad:sink: caps = video/x-raw, width=(int)1024, height=(int)768, format=(string)RGB, framerate=(fraction)30/1, interlace-mode=(string)progressive, colorimetry=(string)sRGB\n",
      "/GstPipeline:pipeline0/GstCapsFilter:capsfilter1.GstPad:sink: caps = video/x-raw, width=(int)1024, height=(int)768, format=(string)RGB, framerate=(fraction)30/1, interlace-mode=(string)progressive, colorimetry=(string)sRGB\n",
      "/GstPipeline:pipeline0/GstMediaSrcBin:mediasrcbin0.GstMediaSrcBinPad:src_0.GstProxyPad:proxypad0: caps = video/x-raw, width=(int)1024, height=(int)768, format=(string)RGB, framerate=(fraction)30/1, interlace-mode=(string)progressive, colorimetry=(string)sRGB\n"
     ]
    }
   ],
   "source": [
    "# Load the app using xmutil\n",
    "#!xmutil loadapp kvs260-aa7\n",
    "\n",
    "# Set up the video pipeline\n",
    "! init_nlp_smartvision.sh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Facedetect Kernel Loaded\n",
      "^C\n",
      "Aborted by signal Interrupt...\n",
      "malloc(): unsorted double linked list corrupted\n"
     ]
    }
   ],
   "source": [
    "# Command to launch the demo \n",
    "! LD_LIBRARY_PATH=/opt/xilinx/lib nlp_sv -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
